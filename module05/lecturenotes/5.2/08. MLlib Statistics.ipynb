{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"uva_seal.png\">  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning with MLlib - Basic Statistics\n",
    "\n",
    "\n",
    "### University of Virginia\n",
    "### DS 5559: Big Data Analytics\n",
    "### Last Updated: Dec 12, 2019\n",
    "\n",
    "---  \n",
    "\n",
    "\n",
    "### SOURCE:\n",
    "\n",
    "1. Learning Spark  \n",
    "2. Spark Documentation  \n",
    "https://spark.apache.org/docs/latest/mllib-statistics.html\n",
    "https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.random.RandomRDDs\n",
    "\n",
    "\n",
    "### OBJECTIVES\n",
    "-  Introduction to basic statistics capabilities  \n",
    "\n",
    "### CONCEPTS\n",
    "\n",
    "- Summary statistics\n",
    "- Correlations\n",
    "- Stratified sampling\n",
    "- Hypothesis testing\n",
    "- Random data generation\n",
    "- Kernel density estimation\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, we provide a short summary of the basic statistics functionality provided for RDDs.  Much of this is supported by the `pyspark.mllib.stat` library.  \n",
    "\n",
    "**Summary Statistics**  \n",
    "\n",
    "`colStats()`  \n",
    "Computes summary of an RDD of vectors. Similar to calling `summary()` on dataframe in R.\n",
    "\n",
    "#### Summary using `colStats()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.stat import Statistics\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "        .master(\"local\") \\\n",
    "        .appName(\"mllib_classifier\") \\\n",
    "        .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "rdd = sc.parallelize([Vectors.dense([2, 0, 0, -2]),\n",
    "                      Vectors.dense([4, 5, 0,  3]),\n",
    "                      Vectors.dense([6, 7, 0,  8])])\n",
    "\n",
    "cStats = Statistics.colStats(rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4., 4., 0., 3.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cStats.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4., 13.,  0., 25.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cStats.variance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cStats.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 2., 0., 3.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cStats.numNonzeros()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6., 7., 0., 8.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cStats.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  0.,  0., -2.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cStats.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation  \n",
    "Currently supports Pearson, Spearman correlation  \n",
    "Takes parameter method. Set to one of ‘pearson’ (default) or ‘spearman’  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8500286768773001"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.mllib.stat import Statistics\n",
    "\n",
    "seriesX = sc.parallelize([1.0, 2.0, 3.0, 3.0, 5.0])\n",
    "seriesY = sc.parallelize([11.0, 22.0, 33.0, 33.0, 555.0])\n",
    "\n",
    "Statistics.corr(seriesX,seriesY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stratified Sampling\n",
    "\n",
    "For stratified sampling, the keys can be thought of as a label and the value as a specific attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 'c'), (2, 'd'), (3, 'f')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# an RDD of any key value pairs\n",
    "data = sc.parallelize([(1, 'a'), (1, 'b'), (2, 'c'), (2, 'd'), (2, 'e'), (3, 'f')])\n",
    "\n",
    "# specify the exact fraction desired from each key as a dictionary\n",
    "fractions = {1: 0.1, 2: 0.6, 3: 0.3}\n",
    "\n",
    "approxSample = data.sampleByKey(False, fractions)\n",
    "\n",
    "approxSample.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hypothesis testing\n",
    "\n",
    "- Pearson’s Independence Test\n",
    "\n",
    "This function computes the goodness of fit. If a second vector to test against is not supplied as a parameter, the test runs against a uniform distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-0e934ef4fc48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgoodnessOfFitTestResult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStatistics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchiSqTest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'vec' is not defined"
     ]
    }
   ],
   "source": [
    "goodnessOfFitTestResult = Statistics.chiSqTest(vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pearson’s Goodness of Fit (GoF) Test \n",
    "\n",
    "This function conducts Pearson's independence test on the input contingency matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-c52fb484bd76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mindependenceTestResult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStatistics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchiSqTest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'mat' is not defined"
     ]
    }
   ],
   "source": [
    "independenceTestResult = Statistics.chiSqTest(mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Kolmogorov-Smirnov Test  \n",
    "\n",
    "`spark.mllib` provides a 1-sample, 2-sided implementation of the Kolmogorov-Smirnov (KS) test for equality of probability distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "Statistics.kolmogorovSmirnovTest(parallelData, \"norm\", 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random data generation\n",
    "\n",
    "`spark.mllib` supports generating random RDDs with i.i.d. values drawn from a given distribution: \n",
    "- uniform\n",
    "- standard normal\n",
    "- Poisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomRDDs.normalRDD(sc, 1000000L, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kernel density estimation\n",
    "\n",
    "KDE is a technique useful for visualizing empirical probability distributions without requiring assumptions about the particular distribution that the observed samples are drawn from. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.stat import KernelDensity\n",
    "\n",
    "kd = KernelDensity()\n",
    "kd.setSample(data)\n",
    "kd.setBandwidth(3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRY FOR YOURSELF (UNGRADED EXERCISES)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Create an RDD containing vectors with 3 columns.  Using `colStats()`, compute the mean and number of nonzero values in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Compute the Spearman correlation between the vectors from (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Generate 10,000 independent samples from a Poisson distribution with mean 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "DS 5559",
   "language": "python",
   "name": "ds5559"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
